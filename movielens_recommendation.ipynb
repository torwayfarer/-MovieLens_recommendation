{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ryN_Fc2sXlIP"
   },
   "source": [
    "# Movie Recommender Systems\n",
    "\n",
    "### **2019/11/14 CoE 202 Activity 3**\n",
    "\n",
    "***Tip> shotcuts for Jupyter Notebook***\n",
    "* Shift + Enter : run cell and select below\n",
    "\n",
    "**(!! Important) In this activity, we excute our model using GPU. Change Hardware Accelerator.**</br>\n",
    "Edit > Notebook settings or Runtime > Change runtime type and select GPU as Hardware accelerator.</br>\n",
    "런타입 > 런타입 유형 변경 > 하드웨어 가속기 > GPU</br>\n",
    "</br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JpE9A4wBXlIS"
   },
   "source": [
    "### Upload the data that you need to Google server\n",
    "These files are in data folder.\n",
    "1. ratings.csv\n",
    "2. movies.csv \n",
    "3. fig1.png (the above picture, optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "L9Fh89pCXlIT",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "0jCIQD3UNNyL",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=\"/content/fig1.png\", width=\"1000\") # If you can't see figure, then upload /img/fig1.png by executing the under code cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZHoM1BZ7OoWC"
   },
   "source": [
    "<center>Fig. 1 Item-based autoencoder </center>\n",
    "\n",
    "A recommender system is a subclass of information filtering system that seeks to predict the \"rating\" or \"preference\" a user would give to an item.<br/>\n",
    "In Project 3, this recommender system is a system to estimate ratings of other movies using ratings from other users similar to those of one user.<br/>\n",
    "And an autoencoder is a neural network that learns to copy its input to its output. It has an internal(hidden) layer that describes a code used to represent the input, and it is constituted by two main parts: an encoder that maps the input into the code, and a decoder that maps the code to a reconstruction of the original input.</br>\n",
    "A item based autoencoder use the ratings of many users in a movie. In other words, the item based autoencoder use column vector of input matrix.</br> \n",
    "A user based autoencoder ues the ratings of many movies in a user. In other words, the user based autoencoder use row vector of input matrix. but in General, the user based autoencoder has less performance than the item based autoencoder. So we use the item based autoencoder.</br>\n",
    "</br>\n",
    "#### Objective> Train deep neural network (autoencoder) to complete movie rating matrix\n",
    "- #### Loss function\n",
    "\n",
    "$$L(M, \\hat{M})=\\sum_{(i,j)\\in E}(M_{ij}-\\hat{M}_{ij})^2 + \\lambda\\sum_{i=1}^{3}\\lVert W_i\\rVert^2_2$$\n",
    "<br/>\n",
    "- #### Update weight and bias\n",
    "$$\\underset{W, b}{\\text{argmin}}\\hspace{0.2em} L(M, \\hat{M})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JwCKUCLVXTso"
   },
   "source": [
    "### Import Library for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code",
    "id": "5phvVC-3XlIQ",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63.0
    },
    "outputId": "9b044ed0-ce87-46d6-b071-209fda954f25"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%tensorflow_version 1.x\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "um_qz7TO55LB"
   },
   "source": [
    "## 1. Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ARMSY7KdXlIV"
   },
   "source": [
    "### MovieLens Dataset (ref.)\n",
    "We use \"MovieLens Latest Datasets\" consisting of 100,000 ratings applied to 9,000 movies by 600 users. Last updated 9/2018.</br>\n",
    "### Fetch MovieLens data\n",
    "All ratings are contained in the file `ratings.csv`. Each line of this file after the header row represents one rating of one movie by one user, and has the following format : userId, movieId, rating, timestamp. The lines within this file are ordered first by userId, then, within user, by movieId. Ratings are made on a 5-star scale, with half-star increments (0.5 stars - 5.0 stars). Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code",
    "id": "zDBpj-qJXlIW",
    "outputId": "09affcf6-9c3f-47b1-c427-1ed9dcfd8194",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>964982400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964980868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964984041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964984100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931\n",
       "5       1       70     3.0  964982400\n",
       "6       1      101     5.0  964980868\n",
       "7       1      110     4.0  964982176\n",
       "8       1      151     5.0  964984041\n",
       "9       1      157     5.0  964984100"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = pd.read_csv('ratings.csv')\n",
    "rating.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1lwDO4k9XlIY"
   },
   "source": [
    "### Ratings statistics\n",
    "Count the number of movies with identical rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code",
    "id": "YvANQacCXlIY",
    "outputId": "607b6e35-ef7a-4bbf-a626-f0ca6b6641b1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The number of movies</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5</th>\n",
       "      <td>1791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>7551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5</th>\n",
       "      <td>5550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>20047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.5</th>\n",
       "      <td>13136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>26818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.5</th>\n",
       "      <td>8551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>13211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        The number of movies\n",
       "rating                      \n",
       "0.5                     1370\n",
       "1.0                     2811\n",
       "1.5                     1791\n",
       "2.0                     7551\n",
       "2.5                     5550\n",
       "3.0                    20047\n",
       "3.5                    13136\n",
       "4.0                    26818\n",
       "4.5                     8551\n",
       "5.0                    13211"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.set_index([\"userId\", \"timestamp\",\"rating\"]).count(level=\"rating\").rename({'movieId': 'The number of movies'}, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "onAY-oIgXlIa"
   },
   "source": [
    "Count the number of users and movies and check the sparsity<br/>\n",
    "There are 610 distinct user and 9724 moives, and sparsity is 1.7%.<br/>\n",
    "And rating.csv contains 100836 (userID, movieID, rating, timestemps) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code",
    "id": "jOHWTOBPXlIa",
    "outputId": "d4922a8e-683c-462d-a2d2-cd30ca947e03",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] 610 users & 9724 movies\n",
      "100836\n",
      "[*] Sparsity: 1.70%\n"
     ]
    }
   ],
   "source": [
    "n_user = len(rating['userId'].unique())\n",
    "n_movie = len(rating['movieId'].unique())\n",
    "n_rating = len(rating['rating'])\n",
    "print(\"[*] %d users & %d movies\" % (n_user, n_movie))\n",
    "print(n_rating)\n",
    "print(\"[*] Sparsity: %.2f%%\" % (n_rating / (n_user * n_movie) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AFf0a9c5XlIc"
   },
   "source": [
    "### Movie list\n",
    "See the movie list including movies' title and genres.<br/>\n",
    "Movie information is contained in the file `movies.csv`. Each line of this file after the header row represents one movie, and has the following format : movieId,title,genres. Movie titles are entered manually or imported from <https://www.themoviedb.org/>, and include the year of release in parentheses. Errors and inconsistencies may exist in these titles. Genres are a pipe-separated list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code",
    "id": "lyWdhNFDXlId",
    "outputId": "f1c97fa3-bf51-4dcc-a139-9321a66df06a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Sabrina (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Tom and Huck (1995)</td>\n",
       "      <td>Adventure|Children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sudden Death (1995)</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  ...                                       genres\n",
       "0        1  ...  Adventure|Animation|Children|Comedy|Fantasy\n",
       "1        2  ...                   Adventure|Children|Fantasy\n",
       "2        3  ...                               Comedy|Romance\n",
       "3        4  ...                         Comedy|Drama|Romance\n",
       "4        5  ...                                       Comedy\n",
       "5        6  ...                        Action|Crime|Thriller\n",
       "6        7  ...                               Comedy|Romance\n",
       "7        8  ...                           Adventure|Children\n",
       "8        9  ...                                       Action\n",
       "9       10  ...                    Action|Adventure|Thriller\n",
       "\n",
       "[10 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movielist = pd.read_csv('movies.csv')\n",
    "movielist.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eWj5Vm5XlIf"
   },
   "source": [
    "Drop **\"timestamp\"** which looks useless in rating(ratings.csv).<br/>\n",
    "We can look at the movie list, there is a movie name and corresponding movie ID. And we can see the genre that corresponds to each movieID. A recommend system will use the genre of the moives to approximately estimate similarity of other movie. And the system will estimate(recommend) a user's empty ratings. Therefore, We don't need timestemp.</br>\n",
    "In fact, we don't use genres because we implement simple recommend system. But i wish that you see how a recommend system works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code",
    "id": "vMsJbhJGXlIf",
    "outputId": "771d2150-4bec-4fff-d0d8-4cc6d9c69dc3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating\n",
       "100831     610   166534     4.0\n",
       "100832     610   168248     5.0\n",
       "100833     610   168250     5.0\n",
       "100834     610   168252     5.0\n",
       "100835     610   170875     3.0"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.drop(['timestamp'], axis=1, inplace=True)\n",
    "rating.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PKQdR5t9XlIh"
   },
   "source": [
    "Scale **\"movieId\"** in between 0 and 9723, **\"userId\"** in between 0 and 609<br/></br>\n",
    "Use pandas.factorize() to using input data converted to numerical data.<br/> \n",
    "labels(Numeric Representation), values = pandas.factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code",
    "id": "8k_VvrCtXlIi",
    "outputId": "120d7a18-cea2-4417-9e98-5f02f81b9d9e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>609</td>\n",
       "      <td>3120</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>609</td>\n",
       "      <td>2035</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>609</td>\n",
       "      <td>3121</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>609</td>\n",
       "      <td>1392</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>609</td>\n",
       "      <td>2873</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating\n",
       "100831     609     3120     4.0\n",
       "100832     609     2035     5.0\n",
       "100833     609     3121     5.0\n",
       "100834     609     1392     5.0\n",
       "100835     609     2873     3.0"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating['movieId'], _ = pd.factorize(rating['movieId'])\n",
    "rating['userId'], _ = pd.factorize(rating['userId'])\n",
    "rating.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HD1w7J6JXlIj"
   },
   "source": [
    "### Item-based autoencoder\n",
    "Rearrange the rating matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code",
    "id": "Ehg_8U5FXlIk",
    "outputId": "11f5f3b0-60d5-4b53-d38d-785879d24f83",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  userId  rating\n",
       "0        0       0     4.0\n",
       "1        1       0     4.0\n",
       "2        2       0     4.0\n",
       "3        3       0     5.0\n",
       "4        4       0     5.0"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = rating[['movieId', 'userId', 'rating']]\n",
    "rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "wX443vTlkXMy",
    "colab_type": "code",
    "outputId": "238cadf5-d3ee-459b-edfd-b069bbbef4a0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    movieId  userId    rating\n",
       "0  0.000000     0.0  1.000000\n",
       "1  0.200000     0.0  0.800000\n",
       "2  0.333333     0.0  0.666667\n",
       "3  0.375000     0.0  0.625000\n",
       "4  0.444444     0.0  0.555556"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.preprocessing import normalize\n",
    "rating[['movieId', 'userId', 'rating']] = normalize(rating[['movieId', 'userId', 'rating']], norm='l1', axis=1)\n",
    "rating.head()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7U8tHCZAXlIm"
   },
   "source": [
    "### Split the ratings for training and test\n",
    "Training : Test = 9 : 1<br/>\n",
    "Divide data set by training data set and training data set by ratio 9:1.<br/>\n",
    "Shape of rating(entire data set) is 100836 $*$ 3</br>\n",
    "Shape of ratingTrain(training data set) is 90752 $*$ 3</br>\n",
    "Shape of ratingTest(test data set) is 10084 $*$ 3</br>\n",
    "</br>\n",
    "pandas.random.choice(range, size, replace)<br/>\n",
    "pandas.iloc() : bring the rows of the corresponding index<br/>\n",
    "And convert pandas.iloc() to numpy array to use.<br/>\n",
    "d1 is number of movies(9724), d2 is number of users(610)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "77StQ1-MXlIm",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "trainIdx = np.random.choice(range(n_rating), int(n_rating * 0.9), replace=False)\n",
    "dataTrain = rating.iloc[trainIdx]\n",
    "\n",
    "testIdx = np.setdiff1d(range(n_rating), trainIdx)\n",
    "dataTest = rating.iloc[testIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code",
    "id": "Faj4m6MUXlIo",
    "outputId": "8936d2f4-d7f3-4f4b-fd1a-086ae071007f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90752, 3)\n",
      "(10084, 3)\n",
      "[[  36.  408.    5.]\n",
      " [ 603.  511.    3.]\n",
      " [ 903.  413.    4.]\n",
      " ...\n",
      " [ 163.  468.    3.]\n",
      " [ 259.  130.    3.]\n",
      " [2198.  134.    4.]]\n",
      "9724.0 610.0\n"
     ]
    }
   ],
   "source": [
    "ratingTrain = np.asarray(dataTrain)\n",
    "ratingTest = np.asarray(dataTest)\n",
    "print(ratingTrain.shape)\n",
    "print(ratingTest.shape)\n",
    "d1, d2 = np.max(ratingTrain[:, 0]) + 1, np.max(ratingTrain[:, 1] + 1)\n",
    "#d1=9723.0\n",
    "#d2=610.0\n",
    "print(ratingTrain)\n",
    "print(d1, d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tOkDJuji6CcZ"
   },
   "source": [
    "## 2. Build a Graph\n",
    "First, make edge(weight) by using matrix representation, and nodes using placeholder. Second, open session to implement our graph(structure of NN). Third, give feed_dict(input of graph) to graph and excute sess.run(learning NN). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cld_DBBgXlIq"
   },
   "source": [
    "### Make edge for weight of NN\n",
    "We use \"tf.sparse_tensor_dense_matmul()\" function instead of  \"tf.layers.dense( )\" function, because of the sparse input and regularization.</br>\n",
    "sparse input(sparse vector) is a vector in which most of the elements are zero. So, sparse input is represented to the input that each user rated for only a few of movies. In fact, since user didn't rate all movies, most of rating element are blank. Thus zero means blank because Ratings are made on a 5-star scale, with half-star increments (0.5 stars - 5.0 stars). So we input matrix of NN is declared SparseTensor, not typical Tensor. Hence we use \"tf.sparse_tensor_dense_matmul()\". cf. dense input(dense matrix) is a vector or matrix in which all of elements are non-zero, i.e. all rate of user is not zero.</br>\n",
    "In case that input is sparse tensor, if you use tf.sparse_tensor_dense_matmul(), then you can compute to use more efficient memory and more faster speed than using a typical tensor matrix multipy.</br>\n",
    "</br>\n",
    "Our graph take input X(?$*$d2 matrix), where ? means that size is not assigned yet. in fact, our feed_dict is d1$*$d2 matrix. => in 1st layer, X$*$W1+b1(d1$*$d2$*$d2$*$100 + d1$*$100) => in 2nd layer, h1$*$w2+b2(d1$*$100$*$100$*$50+d1$*$50)  => in last layer, h2$*$w3(d1$*$50$*$50$*$d2) => shape of X is the same with shape of yhat (that is autoencoder)</br>\n",
    "</br>\n",
    "tf.sparse_tensor_dense_matmul() : function allows multiplying a sparse matrix by a dense matrix by converting blank nodes to zero.</br>\n",
    "tf._.initializer() : intialize weight for initial learning</br>\n",
    "tf.get_variable(name, shape, ) : get an existing variable with parameter. If there are no parameters, then create one. </br>\n",
    "tf.matmul() : matrix multiplication</br>\n",
    "tf.gather_nd() : gather slices into the output tensor with shape specified by indices. In other words, get yhat of specified user  </br>\n",
    "tf.nn.l2_loss() : variable to the power of 2 </br>\n",
    "tf.reduce_sum() : Summation</br>\n",
    "var.op.name.find('weight') : find position of 'weight' in var.op.name. i.e. 'weight1'.find('weight')=0, 'abc'.find('c')=2, 'abc.find('d')=-1.</br>\n",
    "var.op.name : name of variable is determined by operator that generated variable. i.e. w1 = tf.get_variable('weight1', [d2, _units[0]], initializer=w_init) => w1.op.name = weight1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "vsxCuKGCXlIq",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def autoencoder(_X, _units, _l2_lambda, _n_ratings):\n",
    "    from scipy.sparse import identity\n",
    "    w_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    b_init = tf.constant_initializer(0.)\n",
    "    #A=identity(2, dtype='float16', format='dia')\n",
    "    #A = tf.convert_to_tensor(A, dtype=tf.float16)\n",
    "    #_X=tf.sparse_tensor_dense_matmul(_X, A)\n",
    "    #_X=tf.layers.batch_normalization(_X)\n",
    "    #_X = tf.nn.batch_normalization(_X, 1, 0, 1, 1, 0.99)\n",
    "    ## Encoder\n",
    "    '1st Hidden layer'\n",
    "    w1 = tf.get_variable('weight1', [d2, _units[0]], initializer=w_init)\n",
    "    b1 = tf.get_variable('biases1', [_units[0]], initializer=b_init)\n",
    "    h1 = tf.sparse_tensor_dense_matmul(_X, w1) + b1\n",
    "\n",
    "    #################################################\n",
    "\n",
    "\n",
    "    ####### Part 2. Batch normalization  ########\n",
    "    training=tf.placeholder_with_default(False, shape=(), name='training')\n",
    "    h1 = tf.layers.batch_normalization(h1, training = training, momentum=0.9)\n",
    "    #h1 = tf.nn.batch_normalization(h1, 1, 0, 1, 1, 0.99)\n",
    "\n",
    "    ####### Part 3. Dropout  ########\n",
    "    h1=tf.nn.dropout(h1, 0.1)\n",
    "    h1 = tf.nn.relu(h1)\n",
    "    #################################################\n",
    "\n",
    "    '2nd Hidden layer'\n",
    "    w2 = tf.get_variable('weight2', [_units[0], _units[1]], initializer=w_init)\n",
    "    #w1=tf.layers.batch_normalization(w1)\n",
    "    b2 = tf.get_variable('biases2', [_units[1]], initializer=b_init)\n",
    "    h2 = tf.matmul(h1, w2) + b2\n",
    "    #################################################\n",
    "\n",
    "\n",
    "\n",
    "     ####### Part 2. Batch normalization  ########\n",
    "    #training=tf.placeholder_with_default(False, shape=(), name='training')\n",
    "    h2=tf.layers.batch_normalization(h2, training = training, momentum=0.9)\n",
    "    #h2 = tf.nn.batch_normalization(h2, 1, 0, 1, 1, 0.99)\n",
    "\n",
    "     ####### Part 3. Dropout  ########\n",
    "    h2=tf.nn.dropout(h2, 0.1)\n",
    "    h2 = tf.nn.sigmoid(h2)\n",
    "    #################################################\n",
    "\n",
    "\n",
    "    # If you want to simplify the above code, \n",
    "    # use tf.layers.dense(inputs, units, activation)\n",
    "    # i.e. 2st hidden layer => tf.layers.dense(_X, units[0], activation=tf.nn.sigmoid)\n",
    "    \n",
    "    ## Decoder\n",
    "    w3 = tf.get_variable('weight3', [_units[1], d2], initializer=w_init)\n",
    "    \n",
    "    yhat = tf.matmul(h2, w3)\n",
    "    out = tf.gather_nd(yhat, _X.indices)\n",
    "\n",
    "    loss = tf.reduce_sum(tf.pow(out - _X.values, 2)) / _n_ratings\n",
    "    \n",
    "    \n",
    "    ''' L2 regularization '''\n",
    "    all_var = [var for var in tf.trainable_variables() ]\n",
    "    l2_losses = []\n",
    "    for var in all_var:\n",
    "        if var.op.name.find('weight') == 0:\n",
    "            l2_losses.append(tf.nn.l2_loss(var))\n",
    "    \n",
    "    losses = loss + _l2_lambda * tf.reduce_sum(l2_losses)\n",
    "    \n",
    "    return yhat, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R7CmW-AWXlIs"
   },
   "source": [
    "### Set hyperparameters\n",
    "- ***n_epochs*** : The number of epochs\n",
    "- ***lr*** : Learning rate for gradient descent\n",
    "- ***l2_lambda*** : regularization parameter\n",
    "- ***n_units*** : The number of units for each hidden layer\n",
    "- ***n_ratings*** : The number of training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "zqoMMck0XlIs",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\"\"\"parameters\"\"\"\n",
    "n_epochs = 10000\n",
    "lr = 0.5\n",
    "l2_lambda = 0.003\n",
    "n_units = [100, 50]\n",
    "n_ratings = len(ratingTrain)\n",
    "display_step = n_epochs / 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "paNx6uhdXlIu"
   },
   "source": [
    "### Placeholder for sparse input data\n",
    "Make nodes for input into the graph made above.</br>\n",
    "Since our input is sparse data input, declare X with SparseTensor, not typical Tensor, using tf.sparse_placeholder().</br>\n",
    "The size of x is not assigned in order not to specify the size of the matrix(or vector) that represent input.</br>\n",
    "The size of the input may be different, i.e. size of input of traing data set and test data set are different, so do not specify the size of the node. Just when the feed_dict comes in X, the size of the X is flexiblely fitted the feed_dict size.</br>\n",
    "</br>\n",
    "tf.sparse_placeholder(datatype, shape=None, name=None) : make nodes as SparseTensor. SparseTensor has value(element) and corresponding index. So, SparseTensor allow that nodes are blank. This is what difference are between tf.placeholder() and tf.sparse_placeholder(), Tensor and SparseTensor.</br>\n",
    "tf.placeholder(datatype, shape=None, name=None) : make a Tensor that may be used as a handle for feeding a value, but not evaluated directly. It is dense matrix of which there are not blank element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code",
    "id": "9oDg0rtDXlIv",
    "outputId": "eb00427f-039a-4d1a-9163-9d666f9d3a16",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unknown>\n"
     ]
    }
   ],
   "source": [
    "# tf Graph input\n",
    "\n",
    "\n",
    "\n",
    "X = tf.sparse_placeholder(dtype=tf.float32)\n",
    "print(X.shape)\n",
    "#is_train = tf.placeholder(tf.bool, name=\"is_train\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zqvdviakXlIw"
   },
   "source": [
    "### Use the GradientDescentOptimizer\n",
    "So far, we have made graph, but we don't assign the size of edge(matrix representation of weights and bias). Let's assign size of edge.</br>\n",
    "</br>\n",
    "autoencoder() : the above graph</br>\n",
    "tf.Variable(_, trainable) : get variable, If trainalbe is True, add the variable to the graph collection</br>\n",
    "global_step : Optional Variable to increment by one after the variables have been updated. So, global step is variable that represents current step of minimizing. but we don't need it, so global_step is just zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code",
    "id": "ayPrjhMFXlIx",
    "outputId": "27558ade-b44b-4341-beba-2e002fd83763",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-11-244064f55ca7>:25: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:Large dropout rate: 0.9 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.9 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "pred, cost = autoencoder(X, n_units, l2_lambda, n_ratings)\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "#optimizer = tf.train.GradientDescentOptimizer(lr).minimize(cost, global_step=global_step)\n",
    "\n",
    "\n",
    "######Part 1. Momentum Optimizer#########\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=0.1, momentum=0.9).minimize(cost, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xBJH9D-wXlIz"
   },
   "source": [
    "### Create a tensorflow session (EXCUTION PHASE)\n",
    "Tensorflow operations must be executed in the session. The only one session is activated.</br>\n",
    "We must excute NN in the session to learn the neural network we have created.</br>\n",
    "</br>\n",
    "tf.global_variables_initializer() : initializes all weight and bias of NN. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "Z5t5-OrZXlIz",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6O-V_eUXlI2"
   },
   "source": [
    "## 3. Training\n",
    "inputs(feed dictionary) of our graph are ([movieId\tuserId], [rating], [# of movies, # of users]), and keyword of feed_dict is X.</br>\n",
    "We implement our NN to get optimizer and cost function value using feed_dict.</br>\n",
    "feed = {X: (ratingTrain[:, 0:2], ratingTrain[:, 2], [d1, d2])}</br>\n",
    "At the previous code, we make nodes(called X) as sparse tensor, SparseTensor is declared in the form (indices, values, shape).</br>\n",
    "=> we assign feed to matrix with shape(d1$*$d2), where row index is movieID, column index is UserID, element of matrix is Rating in ratingTrain.</br>\n",
    "So, most of element of this matrix is blank, because we have sparse input.</br>\n",
    "But since we use tf.sparse_tensor_dense_matmul() and tf.sparse_placeholder(), it is okay.</br>\n",
    "</br>\n",
    "sess.run((learning objective functions), feed_dictionary) : update NN over cost function using assigned optimizer method by give feed dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code",
    "id": "TvxT3GMBXlI4",
    "outputId": "a4386a91-b916-475b-a8b8-643a3a908a1b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START OPTIMIZATION\n",
      "\n",
      " [*] Epoch: 00000/10000 cost: 4.032363e+00 (Computing time: 0.348s)\n",
      " [*] Epoch: 01000/10000 cost: 1.290644e+00 (Computing time: 4.580s)\n",
      " [*] Epoch: 02000/10000 cost: 1.250115e+00 (Computing time: 4.562s)\n",
      " [*] Epoch: 03000/10000 cost: 1.247388e+00 (Computing time: 4.546s)\n",
      " [*] Epoch: 04000/10000 cost: 1.245868e+00 (Computing time: 4.576s)\n",
      " [*] Epoch: 05000/10000 cost: 1.244044e+00 (Computing time: 4.566s)\n",
      " [*] Epoch: 06000/10000 cost: 1.245430e+00 (Computing time: 4.529s)\n",
      " [*] Epoch: 07000/10000 cost: 1.242719e+00 (Computing time: 4.574s)\n",
      " [*] Epoch: 08000/10000 cost: 1.245438e+00 (Computing time: 4.538s)\n",
      " [*] Epoch: 09000/10000 cost: 1.243166e+00 (Computing time: 4.568s)\n",
      " [*] Epoch: 10000/10000 cost: 1.246996e+00 (Computing time: 4.556s)\n",
      "\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "print(\"START OPTIMIZATION\\n\")\n",
    "start_time = time.time()\n",
    "losses = []\n",
    "for epoch in  range(n_epochs + 1):\n",
    "    feed = {X: (ratingTrain[:, 0:2], ratingTrain[:, 2], [d1, d2])}\n",
    "    _, avg_cost = sess.run((optimizer, cost), feed_dict = feed)\n",
    "    losses.append(np.sqrt(avg_cost))\n",
    "\n",
    "    # DISPLAY\n",
    "    if epoch % display_step == 0:\n",
    "        duration = float(time.time() - start_time)\n",
    "        print(\" [*] Epoch: %05d/%05d cost: %2e (Computing time: %.3fs)\" % (epoch, n_epochs, np.sqrt(avg_cost), duration))\n",
    "        start_time = time.time()\n",
    "print(\"\\nOptimization Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ECFcyFBk0kBi"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "udWdRzZQ5UIj"
   },
   "source": [
    "### plot leaning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code",
    "id": "1AqiiFNrXlI6",
    "outputId": "d76f60d6-134e-4237-95b3-56dc6b52a346",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300.0
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEbCAYAAADeeCN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZxcVZ338c+3tyxkJQsEkhAg7DtG\nWXUQdZDlEX0GBUZHYHQYHZ/HDXXAQXQYnxl1lBl3YBRBFEUWEUVgUGBkl4SdhJAAAUL2hOykk+78\nnj/uqaSqUt19O+mq6uX7fr3uq26de+vec+sm9euz3HMUEZiZmRU01DsDZmbWuzgwmJlZCQcGMzMr\n4cBgZmYlHBjMzKyEA4OZmZVwYDDLQdIUSZGWc+udH7NqcmCwupB0b/qRnVfvvOTUCjySlqV1zotZ\nVTXVOwNm9SKpJSI25tk3IhYCR1c5SzXXne/ABg6XGKzXktQi6UuSZktqlbRc0nWSJhbt8yZJf5S0\nMO2zTtKjkj5UdqxCNdC/S7pa0irg+rIqogsk/UzSGkmvSbq46PPbVCVJOrco7XRJf5L0hqTnJJ1W\ndv73Snpe0oa03yl5q6bSNd4iaVm6xpclfTltO6HoOCdUuN6vVNjv7yTdI2kD8HlJ7Sn9jKLPTyva\n/7iUtqukH6XvZmPKx9ckDerenbXezoHBerObgEuBqcBsQMDZwAOSRqd99gROIKvqeTa9TgOulXRq\nhWN+Eng/8Erat9i/AScCG4DdgH+R9K6ceb0B2BUIYD/gOkk7A0g6BLgR2AfYBIwHfpXnoJKOBR4E\nTgdGAHOAIcDbc+arku8BBwMvAmuAu1L6WUX7nJ1e50TEA5LGAA8DHwFGArPIrvcfya7N+hEHBuuV\nJL0NKPzVfXJEHArsBSwDJgP/kLY9AOwWEVMi4kiyH/S5aVvxD13BamC/iDgE+GDZtunAFOAAsh9w\ngHfkzPJ3I2LfonMOB96S1j8PNALrgIMiYn/guzmP+1WgBVgFHBYRBwO7AJ/J+flKHgQmRcSBwPeB\nq1P6KZKGSxLwgZRW2PYJYA9gBbBPRBxGFkQBTiuUKqx/cGCw3uqoovU7JQXwOjA2pRXq+zcD35K0\nQFIb8AZZCQOyIFHupoiYDxAR7WXbfhURGyNiGbAkpe2SM7/XpteZRWmFzx6cXh+MiFfS+i9yHrfw\nPfw6ImYBRObxnJ+v5IqI2JCO1Q7cAqwkK4mcDhwPTCT7bn9alo+dgQXpftxfdMx+1/4ykLnx2fqC\nP5NV0RQr/MD+DHhn2j4TWAscSPYXe2OFYy3u5Dwri9bb0qty5rHw2baitPLPVmMo4+JjNgJIGtnF\nZ0q+g4jYIOl64O/JSjwvp01/KATRImvJquzKrayQZn2USwxWb5I0uGxpAh4t2ueyiDg6Io4GjgG+\nAFyRthX+Uv2vVM1yCtmPV0fqMc780+n1WEmFUszZHe1c5pH0+l5J+xYSJR2WVpcU7bt3en1fF8es\n9B1cnV7/EjizLA223o8APlR0P94OfJOsPcj6CQcGq7fJZNU/xcvFEXEvcHva55epR8/TZHXt/wMc\nmbY9lV4/KulZ4AVgcI3yntc3gXZgGDBL0nNkjeB5XAxsBEYBz0h6WtIi4Ntp+xy2lp4uk3QP8MPu\nZjAiHgaeA5qBMWQlgF8X7fI94FWykthMSU9JmkNWvXdDyp/1Ew4M1pu9D/gy2Q/WHmT13i8C3wLu\nTfucC9xD1pNoKPBptgaLXiEinibrCTUHGAQsBz5atMsbnXz2QeBY4DekhnOy3lT3pu1tZH/hP05W\nlbQz8FfbmdVritavL7RDpPMsIyud/YislHIAWS+pR4Ev0nkVnfUx8gxuZtUnad+IeL7o/ZfIuuIC\n7B8Rs+uTM7NtufHZrDYekfQyMA+YxNaqsGscFKy3cWAwq41byPr9H0DWc+kxsqqb79czU2aVuCrJ\nzMxKuPHZzMxK9PmqpLFjx8aUKVPqnQ0zsz5lxowZyyJiXKVtfT4wTJkyhenTp9c7G2ZmfUrqDFGR\nq5LMzKyEA4OZmZVwYDAzsxIODGZmVsKBwczMSjgwmJlZCQcGMzMrUfPAIKlR0uOSfldh2yBJ10ua\nK+kRSVOqlY/Zi9Zw2X/PZtna8vngzcwGtnqUGD4FzOpg20eA1yNiKvAfwNerlYk5S9bwnbvnsmLd\nxmqdwsysT6ppYJA0ETiVbLKPSk5n62QhNwLvkJR3zt3u5SVNx+sxBM3MStW6xPCfZPP1bu5g++5k\n0wcWZqZaRTbNYI8rhJuoyxTAZma9V80Cg6TTgCURMaMHjnW+pOmSpi9dunT7jrGjmTAz66dqWWI4\nDniPpHnAL4ETJf2sbJ/XyGa3QlITMJJsftwSEXFlREyLiGnjxlUcHDA3VyWZmZWqWWCIiIsiYmJE\nTAHOAu6OiA+V7XYrcE5aPyPtU5Wf7i1VSQ4MZmYl6j7stqRLgekRcSvwY+BaSXOBFWQBpFpnBtzG\nYGZWri6BISLuBe5N65cUpW8A3l+LPLjEYGZW2YB98tmNz2ZmlQ3cwCA/x2BmVsnADQzp1W0MZmal\nBm5gcBuDmVlFAz4wmJlZqQEbGApcYDAzKzVgA8PWQfQcGszMig3YwMCWQfTMzKzYgA0MW3olOTKY\nmZUYuIFBWzusmpnZVgM3MKRXlxjMzEoN3MDgNgYzs4pyBQZJb5N0eIX0QZKG9ny2qs9Te5qZVZa3\nxHAv8P0O0lf3VGZqyQ+4mZlV1p2qpEo/paM7SO8z/ByDmVmpTudjkPRi0dsjyt4PBcYBq6qRsWpz\nnyQzs8q6mqhnSnoNYFDR+2J/6MH81I4H0TMzq6irwHBNej0HWAr8vmjbeuA54Koq5Kvq5Kk9zcwq\n6jQwRMR5AJLeDswovO8P/HybmVllueZ8jogpAJJ2B94CvBERd1QxX1XnuGBmVlnuXkmSvg3MA24E\nLpH0YUntkv5PtTJXTZ7a08yssrwPuH0O+L9AI1v/2P410A78r+pkrbq2PvnsyGBmVixvieF8siDw\noUJCRKwB5gMHViFfVdenH74wM6uivIFhD+CZiLiuLH0V2bMMfZarkszMSuUNDCuByZJ2KiRIGgPs\nC7xejYxVmwfRMzOrLG9guAcYBUxP76em9cHA3VXIVw14ak8zs0ryBoYvkQ2Wtx/ZH9ljyKqXVgFf\nqUrOqswlBjOzynIFhoiYA0wDrgZmpeUa4Ki0rUuSBkv6s6QnJT0r6Z8r7HOupKWSnkjLR3NfSTdt\naXx2ZDAzK5HrATeAiHgB+NsdOFcrcGJErJXUDNwv6faIeLhsv+sjourPRmx5jsGRwcysRN7nGI6U\n9NeSJklqlPQf6S//n0oakecYkVmb3janpW6/yp7a08yssrxtDJcC15L9mJ8HfAo4BPgg8K95T5aC\nyhPAEuCuiHikwm5/JekpSTdKmtTBcc6XNF3S9KVLl+Y9fdkxslcHBjOzUnkDw6HA4oh4EXgXsAm4\nguwv/lPzniwi2iPicGAi8BZJB5ft8ltgSkQcCtzF1tFdy49zZURMi4hp48Zt32MU8iNuZmYV5Q0M\n44EFaf1AspFWPw7MBHbt7kkjYiVZF9h3l6Uvj4jW9PZHwJu6e+xu56XaJzAz62PyBoY1wO5pdNW9\nyQJC4fPr8xxA0jhJo9L6ELKSx3Nl+0woevsest5PVbG1KsmhwcysWN5eSU8AJwKvpPcPSGoAJgEv\n5DzGBOAaSY1kAeVXEfE7SZcC0yPiVuCTkt4DtAErgHNzHnu7OSyYmZXKGxi+SDZ72xjgQeA64ARg\nOPBQngNExFPAERXSLylavwi4KGeedogbn83MKss7Uc+jksYDoyNiRUq+W1JzRLRXL3vVI0/VY2ZW\nUXcecAuy6p3itD4ZFMAlBjOzjuSewa2/8VhJZmaVDdzA4OcYzMwqGrCBocBVSWZmpQZsYPCcz2Zm\nleVqfJY0uZPNb0TE9g1YVEceRM/MrLK8vZLm0Uk7raSFwEURcW1PZKoW3PhsZlZZd6qS1MmyG3C1\npJN6PIdV46k9zcwqyRsYPg2sA+4jG3L7U2l9Hdm0n3eR/dJ+pgp5rAq5U5KZWUV5q5KmAa+TzcDW\nDiDpcuBF4ADgZGAu8OZqZLIa3MZgZlZZ3hLD+4BGKOn8vzm9f09EbAaeBIb1bPaqx1N7mplVlrfE\nsI5s3oUHJP2arM32PWRtC0vSPmPJShV9gmuSzMwqyxsYfgB8haxKaVpKK/y2fi8NsPdmssl3+hRX\nJZmZlco7uuqlkpYB/0g2BwNkczN8PSJ+KGkEcBTQZ55n8CB6ZmaVdWd01R8AP5A0PL1fU7RtNVkb\nQ59RGCvJccHMrFTuwAAgaRAwKlvV6EJ6RLzS8ad6J0/taWZWWd4hMfYFfgwcW2Fz5D1Ob+SwYGZW\nKu8P+n8Bx1UzI7UmT+BmZlZR3sDwJrLnFr4NzATaqpajGmlIkWGzq5LMzErkDQzzgfaIuKCamaml\nxoZCYKhzRszMepm8Tz5fDOwt6ZRqZqaWClVJ7S4xmJmVyFti+HeyB9p+K2kVsLJoW0TE3j2esypr\nlEdXNTOrJG9g2KNofVRaCvrkL2uhjaHddUlmZiXyBoaf0kcDQEca3MZgZlZR3iExzq1yPmouxQU2\nOzKYmZXoMDCkeZ5bI2JxF3M+53ryWdJg4E/AoHTeGyPiy2X7DCIrnbwJWA6cGRHzujr29tjaK8mB\nwcysWGclhnnAQ2QPts2j46qkvE8+t5JN9LNWUjNwv6TbI+Lhon0+ArweEVMlnQV8HTgzx7G7bUsb\ngwODmVmJrrqrqmy9o6VLkVmb3janpfxX+XTgmrR+I/AOqTqTcDZs6ZVUjaObmfVdnf2lfx5bh9E+\nrydOJqkRmAFMBb4fEY+U7bI78CpARLSlrrFjgGVlxzkfOB9g8uROa7k6VGhjcK8kM7NSHQaGiLim\n0vqOSPNFHy5pFPBrSQdHxDPbcZwrgSsBpk2btl2/7G5jMDOrLPeoqOnH/C3ALpRVH0XET7tz0ohY\nKeke4N1AcWB4jWwioPmSmoCRZI3QPa5QQ+VeSWZmpfIOu30q8HNgeIXNQdaTqKtjjAM2paAwBHgX\nWeNysVuBc8gavc8A7o4qPprc2CA/x2BmViZvieGbwIgdPNcE4JrUztAA/CoififpUmB6RNxKNufD\ntZLmAiuAs3bwnJ1qkHslmZmV686QGOuBs9nOYbcj4ingiArplxStbwDe391jb68GyW0MZmZl8gaG\n6cD4iPhtNTNTaw2S2xjMzMrkHXb7m8Cekr4h6VBJk4uXamawmtzGYGa2rbwlhlvIGpkvSEuxPjvn\ns+TnGMzMynXnB70qTyDXU2ODPB+DmVmZvIGhR5587m0aJPdKMjMrk3fY7R558rm3yXol1TsXZma9\nS2fDbn8YWBoRt6f1DnX3yefeokF+8tnMrFxnJYaryZ5Avj2tdzbsdp8MDFmvJAcGM7NiXVUllQ+7\n3a80SLRvrncuzMx6l84Cw55kk+sU1vudhgbcK8nMrExnw26/XGm9P3GvJDOzbXVn2O1DyEY83Q1o\nLNoUEfGRns5YLTS6V5KZ2TbyDrv9buA3FfYXWeNznwwMcq8kM7Nt5C0xfJFsjuY1ZHMybCQLCG1s\nnf6zz3GvJDOzbeUdRO8wsqCwR3r/GLA/WYD4eBXyVRNZryQHBjOzYnkDw2BgTkSsBDYDg1KD9Gtk\nI6/2SX7y2cxsW3mrklaydQa35cDBkv4R2I/tmLSnt2howFVJZmZl8pYYngcmSxpB9jR0M/CvZIHl\n6SrlreoaXZVkZraNvCWGrwIHA6OAzwMHAXsD84H/U52sVV9jgwODmVm5LgODpEZgYVpejexR4X0k\n7RwRK6qdwWpqbmxgk8fEMDMr0WVgiIh2STOA+RGxZ1F6nw4KkAWG9Rv7bBOJmVlV5G1jmAO0VzMj\n9dDUKNpclWRmViJvYPgsMFHSVyWNr2aGaimrSnJgMDMrljcw3EbWE+kiYKGk9qKlz9bFNDfKbQxm\nZmXy9krqd3MxADQ1NNDmwGBmViJvYLiUjmdw67NclWRmtq1cgSEivlLlfNSFq5LMzLaVq40htSU8\nUCH9KkmP5DzGJEn3SJop6VlJn6qwzwmSVkl6Ii2X5Dn29nKvJDOzbXWnjaFSO8OhwBE5j9EGXBAR\nj0kaDsyQdFdEzCzb776IOC3nMXdIU4MfcDMzK9dpYJB0VdHbvcve7wQcDmzIc6KIKDw9TUSskTQL\n2B0oDww109LkwGBmVq6rEsO5bG10HgucU7ZdwBPdPamkKWQljUrVUMdIehJYAHwuIp6t8PnzgfMB\nJk+e3N3Tb9HUINrc+GxmVqKrwPAKWWCYTDYpz6KibeuB54CLu3NCScOAm4BPR8Tqss2PAXtExFpJ\npwC3APuUHyMirgSuBJg2bdp2/7I3NTbQtjmICKR+2SPXzKzbOg0METEFQNJm4PGIOHZHTiapmSwo\n/Dwibq5wvtVF67+X9ANJYyNi2Y6ctyMtjVkw2NQetDQ5MJiZQf7G5z2B1h05kbI/yX8MzIqIyzrY\nZ1dgcUSEpLeQ9ZpaviPn7UxTY9Ypq23zZlpyPwRuZta/5X2O4eUeONdxwN8AT0sqtEt8kayaioi4\nHDgD+HgaZuMN4Kw0zHdVNDVsLTGYmVkmb4lhh0XE/XQxtEZEfA/4Xm1ylPVKAtwzycysyICuP2lq\nSFVJLjGYmW0xsAPDlsZnlxjMzAo6DAySVki6I63fLem7tctWbQxKVUmtbQ4MZmYFnbUxjALGpfUT\ngMFVz02NDWluBGDDpn43OZ2Z2XbrLDCsAA6TdH96f6CkuyvsFxHxjp7PWvUNbckuf11rn51ryMys\nx3UWGO4F/jdwLNnTzyPISg4FQdbLqM+23A5pyUoM611iMDPborPAcD7wKnAQ8E5gNfB4LTJVK0NT\nYHhjowODmVlBh4EhIlYAn4EtQ2LMjIi31ypjtVAIDOsdGMzMtsj75POW3kuS9khpPfE0dF0N2VJi\ncBuDmVlB7ucYJP2dpEXAi8CLkhZJ+mj1slZ9hcZnlxjMzLbKVWKQdAZwRVnyeOAKSa9HxE09nrMa\nKHRXdWAwM9sqb4nhgvR6H/CptNxH1ivpgo4+1Ns1NohBTQ284V5JZmZb5B1E7xCyGdVOjIh2AEmX\nAy+RzfvcZw1taWS92xjMzLbIW2JoANoKQSFpA9rpYsTU3m5oS5OrkszMiuQtMcwEjpB0M/CrlHYm\nMAmYUY2M1crQlkY/x2BmViRvYPg+2exrp6elIKjh/AnVkFUlOTCYmRXkqkqKiJ8AlwAbyKqOlNYv\niYhrqpe96hviNgYzsxK5Z3CLiK9KuoxsiAyAZyNifXWyVTtDW5pYvHpDvbNhZtZrdGtqzxQIHq1S\nXupiiNsYzMxKDOgZ3ACGNruNwcys2IAPDCOGNLN6w6Z6Z8PMrNcY8IFh9NBm1m9sp7XNpQYzM3Bg\nYOTQFgBWrnepwcwMuggMkiZL2qWT7YdLelvPZ6t2Rg9tBuD19RvrnBMzs96hqxLDPODmwhtJj0n6\nSdH2HwKV5oHuM0a7xGBmViJPd9XisZAOJ3uwraPtfc6oVGJY6RKDmRlQwzYGSZMk3SNppqRnJX2q\nwj6S9B1JcyU9JenIauerUGJ43SUGMzOgmw+47aA24IKIeEzScGCGpLsiYmbRPicD+6TlKLKqqqOq\nmamdd8oCw4p1LjGYmUG+wLC3pKs6eL933hNFxEJgYVpfI2kWsDvZyK0FpwM/jYgAHpY0StKE9Nmq\nGNzcyPDBTSxd01qtU5iZ9Sl5AsNY4Jy0HmXvldK6RdIU4AjgkbJNuwOvFr2fn9JKAoOk84HzASZP\nntzd029jlxGDPV6SmVmSp41BnSzdJmkYcBPw6YhYvT3HiIgrI2JaREwbN27c9hyixK4jBrPIgcHM\nDOgiMEREQ46lMe/JJDWTBYWfR8TNFXZ5jWzyn4KJKa2qxo8YxOJVDgxmZlDbXkkim+xnVkRc1sFu\ntwIfTr2TjgZWVbN9oWDiqCEsWr3Bw2KYmbEdvZIknQK8F1gF3BARf8750eOAvwGelvRESvsiMBkg\nIi4Hfg+cAswF1gPndTd/22PizkPZHLB4VSuTxwytxSnNzHqtTgND6n10DnBWRNwg6TTgN0W7fFLS\neyPi9q5OFBH300W7ROqN9Imus92zxg0bBMBzi1Y7MJjZgNdVVdJhwCbgtvT+s2Q/7u3AOqAZ+Meq\n5a5G9tt1OADL/SyDmVmXgWES8GpErJc0GDiWrHvqh4EpwFqyYTL6tPHDB9HS2MC8ZevqnRUzs7rr\nKjCMAApdSg8FWshKC7dGxArgeWBI9bJXG02NDUwdP4xZi9bUOytmZnXXVWBYDOyfHkg7I6U9keZ+\nhixwLKtO1mrrgAkjmLVwux6rMDPrV7oKDPeTlQheAC4gq0a6BUDSGLIhMV6qZgZr5YAJw1m6ppVl\naz00hpkNbF0FhkvIhqgoPOk8G/h22nZ2Sru3WpmrpQMnjABwqcHMBrxOu6tGxAuSDiZrdG4A7omI\nwiPCD5KNhvpkdbNYG/sXBYa37rPjw2yYmfVVXT7gFhFrgDsrpD9WlRzVyc47tbDLiEHMWugGaDMb\n2Lp6wO3DeQ4SET/tmezUlxugzcy6LjFcTdfDagfQLwLDqCHN3Dt7KWtb2xg2qJZzGJmZ9R55B9Hr\nbOjtPj3nc7Fjp44F4IlXVtY5J2Zm9ZN3PoaNwHXACcAhZcuh1cpcrZ100K5IMOPl1+udFTOzuukq\nMBwP3JD2Oxu4HfgM0BQRzxaWKuexZkYOaWb/XUfwyEvL650VM7O66Wqingcj4kyycZH+jWxspPOA\nxyTdm8ZP6leOnzqG6fNeZ11rW72zYmZWF7naGCJiAfAl4JPAGrLqpbcC/W6M6rfvN56N7Zt56AWX\nGsxsYOoyMEgaKelzZMNiXEc2PtLjwN+mgfT6lWlTdqaxQfzkwX4x0oeZWbd19RzD5cAHyUoGm4Gb\ngf+MiAdqkLe6aGlqYN9dhvPsgtVs3hw0NPSbTldmZrl0VWI4H9iJbLKem8gGzDtd0jeKl2pnstb+\n/m17sXL9Jv5nztJ6Z8XMrObyPMUVZDO1vb+Tfb7QM9npHd6+/3gALrrpaR7+4jvqnBszs9rK+xzD\ngHjArWDkkGYAFq3ewIZN7XXOjZlZbXXVXbUhz1KrzNbSJ0+cCsCZVzxU55yYmdXWDv+oSzqkJzLS\n23z8hCwwPDl/VZ1zYmZWW7kCg6TRkhrL0o6SdCtZ19V+Z0jL1suds9hDcZvZwNFpYJA0RdJTZPM6\nL5H0HkljJf2GbKKeU+mHbQwFf/jsXwDwjTtn1zknZma101WvpG8AB6f10cCPgZlkTz1DNrhevxhy\nu5Kp44cxdfww7pq5mGVrWxk7bFC9s2RmVnVdVSW9lay76rVpGUM2sF4rcBmwZ0ScX9Uc1tln3rkv\nACd/+74658TMrDa6CgxjgTkRcU5EnAPMSemnR8TnImJh3hNJukrSEknPdLD9BEmrJD2RlkvyHrua\nTj10AgBL17SycNUbdc6NmVn1dRUYGoHi8ZBWAETEf2/Hua4G3t3FPvdFxOFpuXQ7zlEV++86HIBj\n/u3uOufEzKz68vRKOkLSi5JeBA4HKLxPywt5ThQRf6I0yPQZd3z6bVvWn3nN3VfNrH/LExhayOZj\nmAIMIuuFNKVs6SnHSHpS0u2SDurB4+6wb5yRTVR32nfvr3NOzMyqq6teSX8ia3yuhceAPSJiraRT\ngFuAfSrtKOl8sgH+mDx5ck0y94Fpk/jCjU8BcP2jr3Dmm2tzXjOzWlNErX73s+cigN9FxMFd7Iqk\necC0iFjW2X7Tpk2L6dOn90j+uvLqivW89Rv3APD8V0+mpalfjgZiZgOApBkRMa3Stl7zyyZpV0lK\n628hy1uvmkZt0s5bJ6zb9+Lb65gTM7PqqVlgkPQL4CFgP0nzJX1E0sckfSztcgbwjKQnge8AZ0Ut\nizM5zfvaqVvWH36xV8UtM7MeUdOqpGqoZVVSwar1mzjs0qzH7s8/ehTHTR1b0/Obme2oPlGV1JeM\nHNrMJ96+NwAf/NEj3PPckjrnyMys5zgwbKfPn7Q//3J61qP2vKsf9QisZtZvODDsgL85ZgpTxw8D\n4F3/8Semz+uTz++ZmZVwYNhBf/jsX7DXuJ0AOOPyh7j24ZfrnCMzsx3jwNAD7r7gBE7cfzwAX7rl\nGaZceButbZ4r2sz6JgeGHnLVuW/mx+dsbeDf7+I7+N7dczr5hJlZ7+Tuqj1sw6Z29v/SHSVpx+w1\nhl+cf3SdcmRmti13V62hwc2NzPvaqfy/920d9eOhF5cz5cLbOOiSO9i8uW8HYjPr/1xiqLIpF97W\n4bYZF7+TMZ4u1MzqoLMSgwNDjdzxzEI+9rPHOt3nJ+e+mRP2G0caMsrMrGocGHqRiODH97/EV2+b\n1a3PTdtjNGe9ZTInHbQLg5sbaW50LaCZbT8Hhl5sw6Z2bpgxny/dUnEq7H7rsEmjePLVlRW3TRw9\nhLb2YNHqDRW3jxs+iOP2HsNvnlxABLQ0NtDYIA6bNJJFqzawqT14bWU2P/euIwbT3CTWt7azfN1G\nAAY3N7Bh02YOnDCCF5aupbVtM00Nom1zMHX8MDa2bWZQUwNzlqxlcHMDQ5ob2XXkEGYtXE1zo9h9\n1BDmLV/PYRNH8uT8VXzk+D25YfqrDGlpZPHqVoYNamJtaxstjQ0cOnEk019+ndFDm3l9/aYOv49j\n9hrD06+tYsTgJhas2nrdR++1M0tWtzJ22CBeXLaWZWuzazj54F25/ZlFAIwe2kxzYwPrN7aztrWN\nUUObGTmkmSMmjeKWJxaUnKelsYHmRjGkpYmp43fi4Re3PpTZ0tRA++Zgl+GDWLKmlbbUHtbS1MCR\nk0cxb9l6hrY08uKydVs+c/zUscxcuJoV6zYyfFATpx22G9c/+gqbI/vuC/dwv12GM3vxGg6cMIJj\n9x7D9dNfZW1rG4funn2HxabtMZr5r7/BqKHNDBuUTRnT2CAeeWlrXgvfccHYYS20NDawYNUGxg4b\nxIghTazd0MbBu4/k7ueW0NLYwIG7jWDMTi388bkljB3Wwq4jB7P7qCHc+eziLf9WJFj1xiYi4Ph9\nxnLXzGzbm/YYzfOL17BmQw/xh6wAAAisSURBVHbOt+4zlhFDmrnjmUW0l7Ub7r/rcOYsWbslfeLo\nIbyxsZ2Pn7A3c5es5banF9Lc2MDGts2MHdbCW/cZx/J1rbywZB2zF69h0s5DOHTiKG57aiHHTx3L\ngpVvbPnO33nAeJ5dsJqF6d/I3Rf8BXuNG9bhv6vOODD0Ma1t7Sxe1cpvn1rAv985u97ZMbNeatLO\nQ7jvCydu12cdGPqxtvbNW9oklq9rZWhL9pfSy8vX8fRrqxg+uInp817n+H3GsmDlBv70/FL+PG/F\nNn/lFAxqaqC1bXMtL8GsbiaOHsL819+odza22wMXnsjuo4Zs12cdGMzMrISfYzAzs9wcGMzMrIQD\ng5mZlXBgMDOzEg4MZmZWwoHBzMxKODCYmVkJBwYzMyvR5x9wk7QU2N6JlscCy3owO32Br3lg8DUP\nDDtyzXtExLhKG/p8YNgRkqZ39ORff+VrHhh8zQNDta7ZVUlmZlbCgcHMzEoM9MBwZb0zUAe+5oHB\n1zwwVOWaB3Qbg5mZbWuglxjMzKyMA4OZmZUYsIFB0rslzZY0V9KF9c7P9pI0SdI9kmZKelbSp1L6\nzpLukjQnvY5O6ZL0nXTdT0k6suhY56T950g6p17XlJekRkmPS/pder+npEfStV0vqSWlD0rv56bt\nU4qOcVFKny3ppPpcST6SRkm6UdJzkmZJOqa/32dJn0n/rp+R9AtJg/vbfZZ0laQlkp4pSuux+yrp\nTZKeTp/5jgpTPnYmIgbcAjQCLwB7AS3Ak8CB9c7Xdl7LBODItD4ceB44EPgGcGFKvxD4elo/Bbgd\nEHA08EhK3xl4Mb2OTuuj6319XVz7Z4HrgN+l978CzkrrlwMfT+v/AFye1s8Crk/rB6Z7PwjYM/2b\naKz3dXVyvdcAH03rLcCo/nyfgd2Bl4AhRff33P52n4G3AUcCzxSl9dh9Bf6c9lX67Mld5qneX0qd\nbsQxwJ1F7y8CLqp3vnro2n4DvAuYDUxIaROA2Wn9CuDsov1np+1nA1cUpZfs19sWYCLwR+BE4Hfp\nH/0yoKn8HgN3Asek9aa0n8rve/F+vW0BRqYfSZWl99v7nALDq+nHrind55P6430GppQFhh65r2nb\nc0XpJft1tAzUqqTCP7iC+SmtT0tF5yOAR4BdImJh2rQI2CWtd3Ttfe07+U/gC8Dm9H4MsDIi2tL7\n4vxvuba0fVXavy9d857AUuAnqfrsR5J2oh/f54h4Dfgm8AqwkOy+zaB/3+eCnrqvu6f18vRODdTA\n0O9IGgbcBHw6IlYXb4vsT4V+0y9Z0mnAkoiYUe+81FATWXXDDyPiCGAdWRXDFv3wPo8GTicLirsB\nOwHvrmum6qAe93WgBobXgElF7yemtD5JUjNZUPh5RNyckhdLmpC2TwCWpPSOrr0vfSfHAe+RNA/4\nJVl10reBUZKa0j7F+d9ybWn7SGA5feua5wPzI+KR9P5GskDRn+/zO4GXImJpRGwCbia79/35Phf0\n1H19La2Xp3dqoAaGR4F9Uu+GFrKGqlvrnKftknoY/BiYFRGXFW26FSj0TDiHrO2hkP7h1LvhaGBV\nKrLeCfylpNHpL7W/TGm9TkRcFBETI2IK2b27OyI+CNwDnJF2K7/mwndxRto/UvpZqTfLnsA+ZA11\nvU5ELAJelbRfSnoHMJN+fJ/JqpCOljQ0/TsvXHO/vc9FeuS+pm2rJR2dvsMPFx2rY/VudKljY88p\nZD14XgD+qd752YHrOJ6smPkU8ERaTiGrW/0jMAf4A7Bz2l/A99N1Pw1MKzrW3wJz03Jeva8t5/Wf\nwNZeSXuR/YefC9wADErpg9P7uWn7XkWf/6f0XcwmR2+NOl/r4cD0dK9vIet90q/vM/DPwHPAM8C1\nZD2L+tV9Bn5B1oayiaxk+JGevK/AtPT9vQB8j7IODJUWD4lhZmYlBmpVkpmZdcCBwczMSjgwmJlZ\nCQcGMzMr4cBgZmYlHBjM6kzSVySFJHcRtF7BgcEGHEn3Fn6IKyzn1jt/ZvXW1PUuZv3WRuDxsrSl\n9ciIWW/iEoMNZAsj4uiy5TZJ5xaVIE6X9ICkDWkClPcVH0DSwZJulrRM0kZJL0n6ZhrUsHi/D0i6\nX9IaSeuVTTzz3vIMSTpW0qNpn8fSsAeFbbtIulbSAkmtaXKX+yR9qHpfkQ1EDgxmnbuebHiCjcBU\n4AZJhwBIOgB4CHgf2XAMc4HJwAXAnZIa0n4XpOMcRzZ8yVyy8fcPr3C+u8gmXGomG0L9l0UDxv0A\n+BAwgmyIg/XAsWTDgpj1GAcGG8j2qNDGMKpsn29GxP5ks4CtI5v973Np24XAsJR+UEQcCHwibTsW\nOFXSULLxfiAbv2dyRBwKjCcbGbbchel8FxTySBaQAPZNrx+PiDdFNojgLsB3t+fizTriwGAD2Uay\nSY2Kl7ayfa4HiIj5wAMp7eD0+ub0+mBEvJzWryv67DTgILJ5BAB+EBEr0/HWR8RzFfJ0bXqdWZRW\nmKTlt+n1akkvSPo98PfAgs4u0qy73PhsA9nCiDi6PDHPXOnVUggclAaoQob+iSw4nUQWnI4HTgbe\nT+VqKbPt4hKDWefeDyBpN7LqIcjq9yGb1wPgWEl7pPW/LvrsdOBZsqomgI9JGpGON7hoboW8jgP+\nJyI+GREnAuen9MMkjenmscw65MBgA9kESQ+XLR8t2+ezkmYBs8jaEzYD30rbvgasJasqelbSs2Rj\n5QM8CNwWEeuBL6e0o4H5kp4km5Hr7G7m92vAcklzJc0Arkrp84EV3TyWWYccGGwgawGOKlsmlu3z\nAbJnGwaRTXRyZkQ8BRARs4BjgF8DrWSNw6+SBY6TImJz2u9bwJlkwaKhaL8nu5nf68kasIcDhwBr\nyGbjOjk8sYr1IE/UY1YmPf38k/R2z4iYV7/cmNWeSwxmZlbCgcHMzEq4KsnMzEq4xGBmZiUcGMzM\nrIQDg5mZlXBgMDOzEg4MZmZW4v8DG5uPlifrBH0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.title(\"Learning curve\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Epochs\", fontsize=14, fontweight='bold')\n",
    "plt.ylabel(\"RMSE of training set\", fontsize=14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w1luZKV2XlI8"
   },
   "source": [
    "## 4. Test\n",
    "inputs(feed dictionary) of our graph are ([movieId\tuserId], [rating], [# of movies, # of users]), and keyword of feed_dict is X</br>\n",
    "We implement out NN to get prediction(yhat) using feed_dict</br>\n",
    "And we get RMSE<br/>\n",
    "pred in Pred = sess.run(pred, feed_dict=feed) is prediction, in other words, pred is yhat(estimate or real value of rate that user rated to a moive)</br>\n",
    "(*reference pred, cost = autoencoder(X, n_units, l2_lambda, n_ratings))</br>\n",
    "</br>\n",
    "idxTest, idxTrain = (index of movieID, index of userID) of matrix[movieID, userID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code",
    "id": "xMfbFyxxXlI8",
    "outputId": "e4df4247-c009-43fd-8e59-2db3c217555e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] RMSE Test: 8.6201e-01\n",
      "[*] RMSE Train 8.2167e-01\n"
     ]
    }
   ],
   "source": [
    "feed = {X: (ratingTrain[:, 0:2], ratingTrain[:, 2], [d1, d2])}\n",
    "Pred = sess.run(pred, feed_dict=feed)\n",
    "\n",
    "idxTest = (ratingTest[:, 0].astype(int), ratingTest[:, 1].astype(int))\n",
    "idxTrain = (ratingTrain[:, 0].astype(int), ratingTrain[:, 1].astype(int))\n",
    "\n",
    "RMSE_Test = np.sqrt(np.sum((Pred[idxTest] - ratingTest[:, 2]) ** 2) / len(ratingTest[:, 0]))\n",
    "RMSE_Train = np.sqrt(np.linalg.norm(Pred[idxTrain] - ratingTrain[:, 2]) ** 2 / len(ratingTrain[:, 0]))\n",
    "\n",
    "print(\"[*] RMSE Test: %.4e\" % RMSE_Test)\n",
    "print(\"[*] RMSE Train %.4e\" % RMSE_Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B4P8W-ReXlI-"
   },
   "source": [
    "# Report</br>\n",
    "\n",
    "Deadline : 2019.11.21 23:59 </br>\n",
    "Submit your soft copy(PJ3_StudentID_Name) to the following email : chaeur@kaist.ac.kr (TA. JongSeong Chae).</br>\n",
    "And please name your email as [CoE202] PJ3_StudentID_Name.</br>\n",
    "I recommend you to refer tensorflow 1.15.0(or 1.x), not 2.x</br>\n",
    "\n",
    "## Report Guidelines\n",
    "- Report length is not limited\n",
    "- Explain your own preprocessing steps and(or) models that you modified.\n",
    "- Annotate on your own source code.\n",
    "- Your report should contain the following contents.\n",
    "\n",
    "### Part 1. Momentum Optimizer\n",
    "Use the \"MomentumOptimizer()\" instead of the GradientDescentOptimizer and compare the RMSE learning curves of the two optimizers. When you use MomentumOptimizer, set the momentum at 0.9 and adjust the learning rate.</br>\n",
    "현재 사용된 Gradient descent optimizer 대신 Momentum optimizer를 사용하고 learning curve의 변화와 RMSE 결과를 비교, 분석하세요 (Momentum optimizer를 사용할 때 momentum 값은 0.9를 사용)</br>\n",
    "*Hint)* tf.train.MomentumOptimizer( )</br>\n",
    "https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/train/MomentumOptimizer\n",
    "\n",
    "### Part 2. Batch normalization\n",
    "Apply \"batch normalization\" to the 1st and 2nd hidden layers of the autoencoder in Part 1, and compare the resulting RMSE learning curves with those obtained above.<br/>\n",
    "첫 번째와 두 번째 hidden layer에 batch normalization 기법을 적용하고 learning curve와 최종 RMSE 결과를 보고 분석하세요.<br/>\n",
    "*Hint)* tf.layers.batch_normalization( )<br/>\n",
    "https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/layers/BatchNormalization\n",
    "\n",
    "### Part 3. Dropout\n",
    "Apply \"Dropout\" to the 1st and 2nd hidden layers of the autoencoder in Part 2, and compare the resulting RMSE learning curves with those obtained above.</br>\n",
    "*Hint)* tf.layers.dropout() or tf.nn.dropout( )<br/>\n",
    "https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/layers/dropout</br>\n",
    "https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/nn/dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "JI4cxUncjAic",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dQ3xR_YeTgoB"
   },
   "source": [
    "# References\n",
    "- Movie recommend system description : https://medium.com/data-science-101/movie-recommendation-system-content-filtering-7ba425ca0920<br/>\n",
    "- Autoencoder description : https://en.wikipedia.org/wiki/Autoencoder<br/>\n",
    "- https://www.tensorflow.org/versions/r1.15/api_docs/python/tf<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "mI4ngV1kjVc7",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Activity_3.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
